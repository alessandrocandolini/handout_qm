
%*******************************************************
% Chapter 2
%*******************************************************



\myChapter{Linear operators in Hilbert spaces}

Operator formulation of standard non-relativistic quantum mechanics heavily
relies on the
theory of linear operators in Hilber spaces.
In particular, the spectral decomposition of self-adjoint operators (bounded and
unbounded ones) is a key
ingredient in formulating the basic rules of quantum mechanics.
This chapter is aimed at providing the necessary mathematical background of functional
analysis employed by non-relativistic quantum mechanics. 
It is a chapter on mathematics, not on quantum physics;
for this reason care has been made to mathematical rigous more than what
will be customary in later chapters.
The Reader interested in how functional analysis applies to the formulation of quantum
mechanics should jump to the next chapters. 
As we shall see, physicists are customary to employ Dirac's notation, a powerful
mnemonic notation which naively speaking however lacks mathematical rigour; a
dictionary is possible to translate Dirac notation to the rigorous theorems of
functional analysis; more on this later on.

\section{Banach and Hilber spaces}

Unless stated otherwise, let $\K $ denote equivalently the field of real numbers
$\R$ or the field of complex numbers $\C$.
(It is possible to develop the theory also for the skew-field of quaternions,
but this case will not be discussed here to avoid dealing with the
non-commutativity of quaternionic product.)


\begin{definition}[norm]
   Let 
   \graffito{Norm}
   $X$ be any vector space over $\K$.
   A ``norm'' on $X$ is any application  $X \to \R$  denoted by $\norm{\cdot}$ 
   satifying the following properties:
   \begin{enumerate} [label=(\alph*)]
	 %[(a)]
      \item 
	 \label{item:norm1}
	 \begin{math}
	    \norm{\varphi} \geq 0  \condition{$\forall \varphi \in X$}
	 \end{math}
	 (nonnegative);
      \item 
	 \label{item:norm2}
	 $\norm{\varphi} = 0$ if and only if $\varphi = 0$
	 (strictly positive);
      \item 
	 \label{item:norm3}
	 \begin{math}
	 \norm{\lambda \varphi} = \abs{\lambda} \norm{\varphi}
	 \condition{$\forall\lambda\in \K$ and $\forall\varphi \in X$}
      \end{math}
	 (positive homogeneity);
      \item 
	 \label{item:norm4}
	 \begin{math}
	 \norm{\varphi + \psi} \leq \norm{
	    \varphi} + \norm{\psi}
	 \condition*{\forall (\varphi,\psi) \in X \times X} 
      \end{math}
	 (the 
	 so-called ``triangle inequality'')
   \end{enumerate}
\end{definition}

\begin{approfondimento}
   \Cref{item:norm1} is not strictly necessary: it follows from
   \cref{item:norm2,item:norm3,item:norm4}.
   In fact, from \cref{item:norm3} $\norm{-\varphi} = \norm{\varphi}$, 
   from \cref{item:norm4} we have thus $\norm{\varphi + (- \varphi)} \leq 
   \norm{\varphi} + \norm{\varphi} = 2 \norm{\varphi}$, and from
   \cref{item:norm2} $\norm{\varphi-\varphi} = 0$.
\end{approfondimento}

A ``normed vector space'' is a vector space equipped with a norm, as formalized
by the following definition.

\begin{definition}[normed vector space]
   A 
   \graffito{Normed vector space}
   ``normed vector space'' over $\K$ is a pair $(X, \norm{\cdot})$ where $X$ is a
   vector  space over $\K$ and $\norm{\cdot}$ is any norm on $X$.
\end{definition}


If $(X, \norm{\cdot})$ is a normed vector space, the norm $\norm{\cdot}$
\emph{induces} a metric (\ie, a notion of distance) and thus a topology on $X$. 
This is proved by the following theorem.

\begin{theorem}
   Let 
   \label{thm:distance-norm}
   \graffito{Distance induced by a norm}
   $(X, \norm{\cdot})$ be any normed vector space over $\K$.
   Let $\fullfunction{d}{X \times X}{\R}$ be the function defined by
   \begin{dmath}[label={distance-norm},frame]
      d( \varphi, \psi) = \norm{\varphi - \psi}
      \condition*{\forall (\varphi,\psi)\in X\times X}
   \end{dmath}.
   Then,  $(X,d)$ is a metric space.
   The metric in \cref{eq:distance-norm} is called the ``metric induced by the
   norm'' on $X$.
\end{theorem}

\begin{proof}
   We need to prove that \cref{eq:distance-norm} defines a metric over $X$,
   \ie, we need to show that $d$  satisfies:
   %\begin{enumerate}[(a)]
   \begin{enumerate} [label=(\alph*)]
      \item 
	 \label{item:distance1}
	 \begin{math}
	    d(\varphi,\psi) \geq 0 \condition{$\forall (\varphi,\psi)\in X
	       \times X$}
	 \end{math}
	 (nonnegativity);
      \item 
	 \label{item:distance2}
	 $d(\varphi,\psi) = 0$ if and only if $\varphi = \psi$
	 (\ie, the only point of $X$ at zero distance from
	 $\psi$ is $\psi$ itself);
      \item 
	 \label{item:distance3}
%	    $d(\varphi,\psi) = d(\psi,\varphi)$ for all 
	 \begin{math}
	    d(\varphi,\psi) = d(\psi,\varphi) \condition{$\forall
	       (\varphi,\psi)\in X
	       \times X$}
	 \end{math}
	 (the distance is a symmetric function of its arguments);
      \item 
	 \label{item:distance4}
	 \begin{math}
	    d(\varphi,\psi) \leq  d(\psi,\eta) + d(\eta,
	    \psi)\condition{$\forall (\varphi,\psi,\eta)\in X
	       \times X\times X $}
	 \end{math} (the so-called ``triangle inequality'').
   \end{enumerate}
   \Cref{item:distance1} follows from property~\ref{item:norm1} of the norm.
   \Cref{item:distance2} follows from property~\ref{item:norm2} of the norm,
   since
      $\norm{\varphi - \psi} = 0 $ if and only if $\varphi - \psi = 0$, \ie, if
      and only if $\varphi = \psi$.
      \Cref{item:distance3} follows from property~\ref{item:norm3} of the norm,
      since 
      \begin{dmath*}[compact]
	 d(\varphi, \psi) = 
      \norm{\varphi - \psi} = \norm { - ( \psi - \varphi)} = \abs{-1}
      \norm{\psi-\varphi} = \norm{\psi-\varphi} 
      = d(\psi,\varphi) 
      \condition*{\forall (\varphi,\psi)\in X \times X}
   \end{dmath*}.
      \Cref{item:distance4}  follows from property~\cref{item:norm4} of the
      norm, since
      \begin{dmath*}[compact]
	 d(\varphi, \psi) = 
	 \norm{\varphi - \psi } = \norm{\varphi - \eta + \eta - \psi}
	 \leq \norm{\varphi - \eta} + \norm{\eta - \psi} 
	 = 
	 d(\varphi, \eta) + d(\eta, \psi) 
      \condition*{\forall (\varphi,\psi,\eta)\in X \times X \times X}
      \end{dmath*}.
      This completes the proof.
\end{proof}

The metric induced by a norm fulfilles the following extra properties,
the proof of which is straightforward and is left to the Reader:
\begin{enumerate}
   \item 
      \begin{math}
	 d(\varphi +\eta , \psi + \eta) = d (\varphi, \psi)
	 \condition{$\forall (\varphi,\psi,\eta) \in X\times X \times X$}
      \end{math}
      (translation invariance);
   \item 
      \begin{math}
	 d(\lambda \varphi ,\lambda \psi) = \abs{\lambda} d (\varphi, \psi)
	 \condition{$\forall (\varphi, \psi)\in X\times X$ and $\lambda\in\K$}
      \end{math}
      (homogeneity);
\end{enumerate}

\Cref{thm:distance-norm}  shows that any normed vector space is naturally
endowed with a notion of distance. Please notice however that a normed vector
space could be equipped also with distances  other than the one induced by the
norm; such distances are not necessary related to the
norm; furthermore, 
\cref{eq:distance-norm}  is not the only one possible distance built from the
norm.

\begin{exercise}
   Let $(X, \norm{\cdot})$ be a normed vector space.
   Let $\fullfunction{d}{X \times X}{\R}$ be the function defined by
   \begin{dmath*}
      d(\varphi,\psi) = \frac{\norm{\varphi - \psi}}{1+ \norm{\varphi - \psi}} 
      \condition*{\forall (\varphi,\psi)\in X\times X}
   \end{dmath*}
   Show that $d$  
   defines a nonhomogeneus, translation invariant metric on $X$.
\end{exercise}

Now that we have a ``natural'' notion of distance in normed vector spaces, 
\ie, \cref{eq:distance-norm},
all the concepts defined for metric spaces applies automatically, in
particular, to normed linear spaces. 
Among these concepts are: continuity, limits, completeness, open sets etc.

\begin{lemma}
Let
$(X, \norm{\cdot})$ be a normed vector space over $\K$.
The following holds:
\begin{dmath}[label={norm-continuity}]
   \Abs { \norm{\psi} - \norm{\varphi}} \leq \norm{\psi-\varphi}
   \condition*{\forall (\psi,\varphi)\in X \times X}
\end{dmath}.
\end{lemma}
\begin{proof}
   The key ingredient is the triangle inequality of the norm.
   For all $(\varphi,\psi)\in X \times X$, we have
   \begin{dgroup*}
   \begin{dmath*}[compact]
      \norm{\varphi} = \norm{\varphi - \psi + \psi}
      \leq \norm{\varphi - \psi} + \norm{\psi}
   \end{dmath*}
   \begin{dsuspend}
      and
   \end{dsuspend}
   \begin{dmath*}[compact]
      \norm{\psi} = \norm{\psi - \varphi + \varphi}
      \leq \norm{\varphi - \psi} + \norm{\psi}
   \end{dmath*}.
\end{dgroup*}
Thus,
\begin{dgroup*}
   \begin{dmath*}[compact]
      \norm{\varphi} -\norm{\psi} 
      \leq \norm{\varphi - \psi} 
   \end{dmath*}
   \begin{dmath*}[compact]
      \norm{\psi} -\norm{\varphi}
      \leq \norm{\varphi - \psi} 
   \end{dmath*}.
\end{dgroup*}
which is exactly the meaning of \cref{eq:norm-continuity}.
(To see this even more explicitly, it is enough to discuss the three cases
$\norm{\psi} < \norm{\varphi}$,
$\norm{\psi} = \norm{\varphi}$,
$\norm{\psi} > \norm{\varphi}$,
and remember that $\norm{\varphi-\psi}\geq 0$.
)
\end{proof}

\begin{theorem}
Let
\graffito{Continuity of the norm}
$(X, \norm{\cdot})$ be a normed vector space over $\K$.
The norm $\norm{\cdot}$ is continuous on $X$ (with respect to the metric
induced by the norm).
\end{theorem}

\begin{proof}
We need to show that  $\forall \psi \in X$ the following holds:
for all real numbers $\varepsilon > 0$, 
there exists a real number $\delta > 0$ such that, for all $\varphi \in X$, if
$d(\psi,\varphi)<\delta$ then 
$\tilde{d}( \norm{\psi},
\norm{\varphi}) < \varepsilon$, where $\tilde{d}$ is the euclidean distance in
$\R$.

   Notice  that 
   $d( \psi, \varphi) < \delta $ means 
\begin{dmath*}[compact]
   \norm{\psi-\varphi} < \delta
\end{dmath*},
and 
$\tilde{d}( \norm{\psi},
   \norm{\varphi}) < \varepsilon$ means 
\begin{dmath*}[compact]
   \abs{\norm{\psi}-\norm{\varphi} }< \epsilon
\end{dmath*}.
Using \cref{eq:norm-continuity}, it is enough to choose any $0<\delta < \epsilon$.
\end{proof}

Let us recall an important fact about Cauchy sequencies.
\graffito{Completeness of a metric space}
Give any metric space $(X,d)$, a convergent sequence in $X$ is also a Cauchy
sequence.
The converse of this statement is not generally true  however, \ie, there
exists metric spaces where some Cauchy sequences do not need to converge.
\begin{approfondimento}
   A typical counter-example works as follow.
   Consider a sequence $(x_{n})_{n}$ of rational numbers in $\R$ which is
   convergent to some irrational
   number. 
   Thus, $(x_{n})_{n}$ is a Cauchy sequence.
   Now, consider the same sequence as a sequence in $\Q$: of course, it is
   still a Cauchy sequence, but this time it is not convergent.
\end{approfondimento}
A metric space is ``complete'' if \emph{all} Cauchy
sequencies are convergent. 

\begin{definition}[Banach space]
   Let
   \graffito{Banach space}
   $(X,\norm{\cdot})$ be a normed vector space over $\K$.
   If $(X,d)$ (where $d$ is the metric induced by the norm) is complete,
   $(X,\norm{\cdot})$ is called a ``Banach space''.
\end{definition}

We are almost ready to introduce the notion of Hilber space, which is the setting
where we will develop the operator formulation of non-relativistic quantum mechanics. 
The first ingredient is the ``inner product'', defined below.

In 
\graffito{Complex numbers notation}
the following,  for every $z\in\C$ we will denote the ``complex conjugate'' of $z$ with
$\conj{z}$ and the ``modulus''  of $z$ with $\abs{z}$.
Remember that $z = \Re{z} + \ii \Im{z}$ (where $\Re{z}$ and $\Im{z}$ are the
real and imaginary parts of $z$, respectively), $\conj{z} = \Re{z} - \ii \Im{z}$
and $\abs{z}^{2} = z\conj{z}$.
The inverse of $z\neq 0 $ is $z^{-1} = \conj{z} / \abs{z}^{2}$.
We have $z\in \R$ if and only if $\conj{z} = z$.
The complex conjugation satisfies the ``involution'' property: $\conj{\left(
      \conj{z}\right)} = z$.
Furthermore, $\conj{\left( z_{1}z_{2}\right)} = \conj{z_{1}} \conj{z_{2}}$,
$\conj{\left( z_{1} \pm z_{2}\right)} = \conj{z_{1}} \pm \conj{z_{2}}$, and
$\abs{ z_{1}z_{2}} = \abs{z_{1}} \abs{z_{2}}$. 

\begin{definition}[inner product]
   Let
   \graffito{Inner product}
   $X$ be a vector space over $\K$. 
   A ``inner product'' on $X$ is any application
   $X\times X \to \K$, hereafter denoted by $\braket{\cdot|\cdot}$, satisfying
   the following properties:
   \begin{enumerate} [label=(\alph*)]
      \item 
	 \label{item:inner1}
	 \begin{math}
	    \braket{\varphi| \psi + \eta} = \braket{\varphi|\psi} +
	    \braket{\varphi|\eta}
	    \condition*{\forall ( \varphi,\psi, \eta) \in X \times X \times X}
	 \end{math};
      \item 
	 \label{item:inner2}
	 \begin{math}
	    \braket{\varphi| \lambda \psi } = \lambda \braket{\varphi|\psi} 
	    \condition{$\forall ( \varphi,\psi) \in X \times X$ and $\lambda
	       \in \K$}
	 \end{math};
      \item 
	 \label{item:inner3}
	 \begin{math}
	    \braket{\varphi| \psi } = \conj{\braket{\psi|\varphi} }
	    \condition{$\forall ( \varphi,\psi) \in X \times X$}
	 \end{math};
      \item 
	 \label{item:inner4}
	 \begin{math}
	    \braket{\varphi| \varphi } \geq 0 
	    \condition{$\forall \varphi \in X $}
	 \end{math};
      \item 
	 \label{item:inner5}
	 \begin{math}
	    \braket{\varphi| \varphi } = 0 
	 \end{math} 
	 if and only if $\varphi = 0$.
   \end{enumerate}
\end{definition}

Several remarks are in order.
\begin{remark}
\Cref{item:inner1,item:inner2} implies that the inner product is
\emph{linear} on the \emph{second} component, namely:
\begin{dmath*}[frame]
	 \braket{ \varphi | \lambda \psi + \mu \eta } 
	 = \lambda \braket{\varphi | \psi}
	 + \mu \braket{\varphi | \eta}
%	 \condition{$\forall (\varphi,\psi,\eta)\in X\times X \times X$ and
%	    $\forall (\lambda,\mu)\in \K \times \K$}
      \end{dmath*},
      for all 
	 $(\varphi,\psi,\eta)\in X\times X \times X$ and
	    for all $(\lambda,\mu)\in \K \times \K$.
      \Cref{item:inner3} together with 
\cref{item:inner1,item:inner2} implies that the  inner product in general is 
\emph{conjugate-linear} (or anti-linear) on the \emph{first} component, namely
\begin{dmath*}[frame]
	 \braket{ \lambda \varphi + \mu \eta | \psi  } 
	 = \conj{\lambda} \braket{\varphi | \psi}
	 + \conj{\mu} \braket{\varphi | \eta}
%	 \condition{$\forall (\varphi,\psi,\eta)\in X\times X \times X$ and
%	    $\forall (\lambda,\mu)\in \K \times \K$}
      \end{dmath*},
      for all 
	 $(\varphi,\psi,\eta)\in X\times X \times X$ and
	    for all $(\lambda,\mu)\in \K \times \K$.
      Of course, if $\K = \R$, $\conj{\lambda} = \lambda$, $\conj{\mu} = \mu$
      and the inner product becomes linear also on the first component (thus,
      it is \emph{bi}linear); but this is not the case if $\K = \C$, where
      complex conjugation appears. 
   \end{remark}
\begin{remark}
   \Cref{item:inner2} is a matter of choice.
   Some authors prefer a different convention:
   \begin{dmath*}
      \braket{\lambda \varphi|\psi} = \lambda \braket{\varphi|\psi}
      \condition{$\forall(\varphi,\psi)\in X \times X$ and $\lambda \in \K$}
   \end{dmath*};
   with this convention, the inner product would become linear on the first
   component and conjugate-linear on the second one.
   The convetion of having the inner product linear on the second component is
   the one most often employed by physicists, and the one used in this notes.
\end{remark}
\begin{remark}
   Regarding \cref{item:inner4,item:inner5}, one may wonder what does mean
   $\braket{\varphi|\varphi} \geq 0$, since we expect $\braket{\varphi|\varphi}\in \K$,
   and if $\K=\C$ it might seem that the inequlity does not make sense.
   Actually, from \cref{item:inner3} 
   \begin{dmath*}
      \braket{\varphi | \varphi } = \conj{\braket{\varphi | \varphi}} 
      \condition*{\forall \varphi \in X}
   \end{dmath*},
%   thus $\braket{\varphi|\varphi}\in\R$ for all $\varphi\in X$, even if $\K = \C$.
\end{remark}
\begin{remark}
Some authors prefer the notation
$(\varphi,\psi)$ instead of $\braket{\varphi|\psi}$;
the notation $\braket{\varphi|\psi}$ is closer to the one uses by physicists
and it is the first step towards the introduction of Dirac's notation.
(Dirac's notation is more than simply writing the inner product this way; we
will discuss this point in connection with the spectral theorem of linear
operators.)
In Dirac notation the vector $\psi$ is denoted by $\ket{\psi}$, and it is
called ``ket'';
there is a ``kind of conjugation'' (more on this later on) that converts the
analogous ``ket'' $\ket{\varphi}$ to a so-called ``bra'' $\bra{\varphi}$ and
the inner product is considered as a product between a ``bra'' and a ``ket''
(resulting in a ``braket''!).
Of course, this is 
just a naming convention.
\end{remark}


\begin{definition}[inner product space]
   A 
   \graffito{Inner product space}
   ``inner product space'' over $\K$ is a pair $( X, \braket{\cdot|\cdot})$, where
   $X$ is a vector space over $\K$ and
   $\fullfunction{\braket{\cdot|\cdot}}{X\times X}{\K}$ is  an
   inner product on $X$.
\end{definition}

Any 
\graffito{Norm induced by inner product }
inner product space is naturally endowed with a norm coming from the inner
product. 
   Let $(X, \braket{\cdot|\cdot})$ be an inner product space over $\K$.
   Let $\fullfunction{\norm{\cdot}}{X}{\R}$ defined by
   \begin{dmath}[frame,label={norm-inner}]
      \norm{\psi} = \left(\braket{\psi|\psi}\right)^{1/2}
      \condition*{\forall\psi\in X}
   \end{dmath}.
   Observe that such $\norm{\cdot}$  is well-defined, since $\braket{\psi|\psi}
   \geq 0$ for every $\psi\in X$.
   We shall prove in a moment that $\norm{\cdot}$ is actually a norm on $X$,
   this justify the notation $\norm{\cdot}$.
   Such norm  is the ``norm induced by the inner product''.
   Before proving this, we need a preliminary but extremely important result,
   which goes under the name of 
Cauchy-Schwarz inequality.

Cauchy-Schwarz inequality is of major importance. 
It is a key ingredient in several proofs of functional analysis. 
It has important implications also outside the realm of analysis. 
For example, the general formulation of the Heisenberg uncertainty principle in
quantum mechanics (or the analogous time-bandwidth uncertainty principle for
temporal signal
transmission) is derived
using the Cauchy-Schwarz inequality.
\begin{theorem}[Cauchy-Schwarz inequality]
   Let 
   \graffito{Cauchy-Schwarz inequality}
   $(X, \braket{\cdot|\cdot})$ be an inner product space.
   The following holds:
   \begin{dmath}[label={cs},frame]
      \abs{ \braket{\varphi|\psi}} \leq \norm{\varphi} \norm{\psi}
      \condition*{\forall (\varphi,\psi) \in X \times X}
   \end{dmath}.
\end{theorem}

\begin{remark}
   In \cref{eq:cs} we are using the definition \cref{eq:norm-inner} but it is
   important to emphasize that we are \emph{not} using (in both the statement and in
   the proof of Cauchy-Schwarz inequality) the fact that \cref{eq:norm-inner}
   is a norm.  We don't know at this point that \cref{eq:norm-inner} defines a
   norm, we will prove that in the next theorem, using the Cauchy-Schwarz
   inequality. 
\end{remark}

\begin{proof}
   We distinguish two cases.

\end{proof}

\begin{theorem}
   Let 
   $(X, \braket{\cdot|\cdot})$ be an inner product space over $\K$. 
   $(X, \norm{\cdot})$ with $\norm{\cdot}$ defined by \cref{eq:norm-inner} is
   a normed vector space over $\K$. 
\end{theorem}

\begin{proof}
   We need to check that \cref{eq:norm-inner} makes sense and that it satisfies
   \cref{item:norm1,item:norm2,item:norm3,item:norm4} of the
   definition of the norm.
\end{proof}

\begin{theorem}
   Let 
   \graffito{Continuity of inner product}
   $(X, \braket{\cdot|\cdot})$ be an inner product space over $\K$. 
   $\braket{\cdot}{\cdot}$ is a continuous function of both arguments.
\end{theorem}

The following result is basic to establish the later theorem
\begin{lemma}[polarization identity]
\end{lemma}
\begin{theorem}[parallelogram law]
   Let 
   \graffito{Parallelogram law}
   $(X, \norm{\cdot})$ be a normed vector space over $\K$. 
   The norm $\norm{\cdot}$ comes from an inner product \emph{if and only if}
   the following identity (known as ``parallelogram law'') holds:
   \begin{dmath}
      \norm{\varphi + \psi}^{2} + \norm{\varphi - \psi}^{2} = 2
      \norm{\varphi}^{2} + \norm{\psi}^{2}
      \condition*{\forall (\varphi,\psi)\in X \times X}
   \end{dmath}.
\end{theorem}

\section{Canonical prototypes of Banach and Hilbert spaces}

\section{Orthogonality}
\section{Orthonormal basis}
